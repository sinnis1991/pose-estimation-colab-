{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A generative feature-to-image robotic vision framework for 6-D pose measurement of metal parts.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPmLlGwp042auV3EN5Ttpp9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinnis1991/pose-estimation-colab-/blob/master/A_generative_feature_to_image_robotic_vision_framework_for_6_D_pose_measurement_of_metal_parts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWCv_fEAM_66",
        "colab_type": "text"
      },
      "source": [
        "<center><font size=6> A generative feature-to-image robotic vision framework for 6-D pose measurement of metal parts</font></center>  \n",
        "\n",
        "---\n",
        "\n",
        "<p align=\"left\"> This notebook gives an example of the proposed 6-D pose estimation method. \n",
        "It is based a unique <font color=#04a1e5> generative feature-to-image framework</font> constructed through deep generative models. \n",
        "A specific algorithm is used to indirectly infer the pose through an <font color=#F08519>interactive regression pose estimation process </font>.\n",
        "The code is divided into these 2 parts. We will give a brief instruction of these 2 parts of codes' work. \n",
        "\n",
        "<font size=2>(P.S. If you can't see the instruction clearly, please change the notebook style: Tools ==> Settings ==> Site ==> Theme ==> dark)</font>\n",
        "<br/><br/>\n",
        "\n",
        "\n",
        "<center><font size=5 color=#04a1e5> generative feature-to-image framework</font></center>  \n",
        "<center><font color=#04a1e5>==================================================================================================================</font></center>\n",
        "<img align=\"right\" width=\"539\" height=\"300\" src=\"https://raw.githubusercontent.com/sinnis1991/colab-pose-VAE/master/ims/figure/1.png\"/></img>\n",
        "\n",
        "This framework represents a model (generator)ï¼š \n",
        "\n",
        "<center>${x_t} = G(z)$</center>  \n",
        "\n",
        "whose input is a low-dimensional feature $z$ representing any pose $y$ freely, \n",
        "and the corresponding output is a standard generated image ${x_t}$ describing the object in pose $y$. \n",
        "In probability learning, it means to construct a conditioned probability model: \n",
        "\n",
        "<center>$x$~$p(x|z)$</center>\n",
        "\n",
        "establishing a reverse mapping from feature to image,\n",
        "as generative models. In particular, there's a restrction for the input $z$ :\n",
        "\n",
        "<center>$z$~$q(z)$</center>\n",
        "\n",
        "<br/><br/>\n",
        "\n",
        "In this program, the model is specified as :\n",
        "\n",
        "**Input :** feature <font color=#F08519>z</font>  (a 6-dimensional vector)  &nbsp; &nbsp; &nbsp;-----------> \n",
        "      &nbsp; &nbsp; &nbsp;**Output :** image <font color=#04a1e5>x</font>  (the corresponding binary contour image (128x128))\n",
        "\n",
        "In this model, the input could represent any pose within the range and the generator could \n",
        "precisly generate the image of that pose, even that pose and image do not exist in its training dataset. <br/>\n",
        "\n",
        "<font size = 6>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</font> \n",
        "<left><font size = 6>feature</font> <font size=6 color=#F08519>&nbsp;$z$</font>   (5th and 6th dimension) \n",
        "<font size = 6>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</font> \n",
        "<font size = 6>image</font> <font size=6 color=#04a1e5>&nbsp;$x$</font></left>\n",
        "\n",
        "\n",
        "![Alt Text](https://raw.githubusercontent.com/sinnis1991/colab-pose-VAE/master/ims/figure/combine(32)_small.gif)\n",
        "\n",
        "\n",
        "<br/><br/>\n",
        "\n",
        "<center><font size=5 color=#F08519> interactive regression pose estimation process</font></center>  \n",
        "<center><font color=#F08519>==================================================================================================================</font></center>\n",
        "\n",
        "\n",
        "<img align=\"right\" width=\"600\" height=\"403\" src=\"https://raw.githubusercontent.com/sinnis1991/colab-pose-VAE/master/ims/figure/2_move.gif\"/></img>\n",
        "\n",
        "This pose estimation process is based on the previously constructed generator model.<br/>\n",
        "(1) It starts with a random feature and its generated image:<br/>\n",
        "<center>( <font color=#F08519>${z_0}$</font>  , <font color=#04a1e5>${x_0}$</font> )</center>\n",
        "\n",
        "(2) In the following iterations, it will interactively correct the input feature and the output generated image, to gradually regress them to the target answer.<br/>\n",
        "<left>$z$ --> $x$ : from feature to generate image<br/>\n",
        "$x$ <-- $z$ : backwardly correct the feature by estimating the distance with the target image</left>\n",
        "\n",
        "(3) Finally, it will get an optimized feature and image:<br/>\n",
        "<center>( <font color=#F08519>${z_n}$</font>  , <font color=#04a1e5>${x_n}$</font> )</center>\n",
        "\n",
        "They are the final answers for the target pose.\n",
        "\n",
        "\n",
        "<br/><br/>\n",
        "In particualr, this estimation process can be **parallel**: \n",
        "<br/>initiate start points from multiple random z and converge to the same target. \n",
        "This gains a remarkble ensurance to get a right answer.\n",
        "\n",
        "\n",
        "<font size = 6>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</font> \n",
        "<left><font size = 6>feature</font> <font size=6 color=#F08519>&nbsp;$z$</font>   (multiple) \n",
        "<font size = 6>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</font> \n",
        "<font size = 6>image</font> <font size=6 color=#04a1e5>&nbsp;$x$</font></left>\n",
        "\n",
        "\n",
        "![Alt Text](https://raw.githubusercontent.com/sinnis1991/colab-pose-VAE/master/ims/figure/combine(complete)_small.gif)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHtRS2h-t3HI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please mount your google drive. There must be at least 5GB free space.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHzLUuljYGqW",
        "colab_type": "text"
      },
      "source": [
        "<center><font size=6> Choose a target object for the task </font></center>\n",
        "</br>\n",
        "\n",
        "![ims](https://raw.githubusercontent.com/sinnis1991/colab-pose-VAE/master/ims/figure/models.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8njfnaKEsKIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# choose the index of the object\n",
        "\n",
        "object_index = \"1\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUagsyYntBzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libararies\n",
        "\n",
        "try:\n",
        "  # Colab only\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "!rm -rf colab-pose-VAE\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import json\n",
        "import moviepy.editor as mvp\n",
        "from google.colab import files\n",
        "from lucid.misc.gl.glcontext import create_opengl_context\n",
        "\n",
        "!git clone https://github.com/sinnis1991/colab-pose-VAE.git\n",
        "import sys\n",
        "sys.path.insert(0, \"./colab-pose-VAE\")\n",
        "import os\n",
        "\n",
        "from math import pi,cos,sin\n",
        "from OpenGL.GL import *\n",
        "from OpenGL.GLU import *\n",
        "from opengl_model import estimate_3D_to_2D, gl_ob\n",
        "\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBa0ep6ut0gU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}